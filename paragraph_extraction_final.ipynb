{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paragraph_extraction_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af7wc3JqX34K"
      },
      "source": [
        "#Importing necessary libraries and modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JZYPaIQASx3",
        "outputId": "fb0164c4-cf4e-4eab-8189-a38f87ec607e"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        " \n",
        " \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy \n",
        "from spacy import displacy\n",
        "\n",
        "\n",
        "!pip install goslate\n",
        "!pip install googletrans==3.1.0a0\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "Collecting goslate\n",
            "  Downloading https://files.pythonhosted.org/packages/39/0b/50af938a1c3d4f4c595b6a22d37af11ebe666246b05a1a97573e8c8944e5/goslate-1.5.1.tar.gz\n",
            "Collecting futures\n",
            "  Downloading https://files.pythonhosted.org/packages/05/80/f41cca0ea1ff69bce7e7a7d76182b47bb4e1a494380a532af3e8ee70b9ec/futures-3.1.1-py3-none-any.whl\n",
            "Building wheels for collected packages: goslate\n",
            "  Building wheel for goslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for goslate: filename=goslate-1.5.1-cp37-none-any.whl size=11412 sha256=be9e78486a581dd899e0beed2b2a3f0ef48a68d012a69185d2d8a1e7e72e008e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/7f/28/6f52271012a7649b54b1a7adaae329b4246bbbf9d1e4f6e51a\n",
            "Successfully built goslate\n",
            "Installing collected packages: futures, goslate\n",
            "Successfully installed futures-3.1.1 goslate-1.5.1\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.5MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2021.5.30)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Collecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp37-none-any.whl size=16368 sha256=62920c63e70a4d761363abfeea8dc1e057387153a857c6cd7f0a7e108a7e5a95\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hstspreload, sniffio, hpack, hyperframe, h2, h11, httpcore, rfc3986, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zboQWIP-YUU2"
      },
      "source": [
        "#Translating text from one language to another"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHo4iWbaJqT"
      },
      "source": [
        "FUNCTION TO TRANSLATE A SINGLE QUESTION(STRING)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "42Z303tDIxAy",
        "outputId": "6ac9a460-5f76-4bb4-9954-05dff3c844df"
      },
      "source": [
        "def translate_2(to_translate, to_langage=\"auto\", langage=\"auto\"):\n",
        "        import goslate\n",
        "        gs = goslate.Goslate()\n",
        "     #   print(gs.translate(to_translate, 'en'))\n",
        "        result = gs.translate(to_translate,'en')\n",
        "        return result\n",
        "translate_2(\"భారత దేశ ప్రాధాని ఎవరు?\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Who is the Prime of India?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wU4pGojaR9g"
      },
      "source": [
        "FUNCTION TO TRANSLATE TWO LISTS FROM TELUGU TO ENGLISH"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtxRYVkg_vOn",
        "outputId": "2b2adaf6-e840-41b2-9f5f-afefd0c7efc0"
      },
      "source": [
        "def translate(quest_list,ans_list):\n",
        "  from googletrans import Translator\n",
        "  translater=Translator()\n",
        "  out_quest=[] #tranlated list\n",
        "  out_ans=[]\n",
        "  for quest in quest_list:\n",
        "    translated=translater.translate(quest,dest=\"en\")\n",
        "    out_quest.append(translated.text)\n",
        "  for ans in ans_list:\n",
        "    translated=translater.translate(ans,dest=\"en\")\n",
        "    out_ans.append(translated.text)\n",
        "  return out_quest,out_ans\n",
        "(Target_Questions,Target_Answers)=translate([\"భారత దేశ ప్రధాని ఎవరు?\",\"అడ్వెంచర్స్ ఆఫ్ టామ్ సాయర్” రచయిత ఎవరు?\"],[\"మోడీ\"])\n",
        "print(Target_Questions,\"and\",Target_Answers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Who is the Prime Minister of India?', \"Who is the author of 'Adventures of Tom Sawyer'?\"] and ['Modi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vytx5ktSah15"
      },
      "source": [
        "FUNCTION TO TRANSLATE A STRING FROM ENGLISH TO TELUGU LANGUAGE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl3vyDWX_12F",
        "outputId": "ad985549-42fc-454d-ae5a-951e31bb7ccc"
      },
      "source": [
        "def translate2(quest):\n",
        "  from googletrans import Translator\n",
        "  translater=Translator()\n",
        "  out=translater.translate(quest,dest=\"te\")\n",
        "  print(out.text)\n",
        "  return out.text\n",
        "print(translate2(\"country\"))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "దేశం\n",
            "దేశం\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD6J880Uas7K"
      },
      "source": [
        "**#FUNCTION TO CLASSIFY THE ANSWER TYPE OF THE QUESTION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsoSPymARhcK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "01aa9e47-7e59-44f9-ac88-37d99585cd6a"
      },
      "source": [
        "def Question_Classification(user_input):\n",
        "  qa=open(\"/content/drive/MyDrive/Odqa_telugu_Train_set.txt\",\"a\")\n",
        "  qa.write(\"    :\"+user_input+\"\\n\")\n",
        "  qa.close()\n",
        "  f=open(\"/content/drive/MyDrive/Odqa_telugu_Train_set.txt\",\"r\")\n",
        "  classes=[]\n",
        "  queries=[]\n",
        "  new_label=[]\n",
        "  for line in f:\n",
        "\n",
        "    line=line.rstrip('\\n')\n",
        "    classes.append((line.split()[0]).split(\":\")[0])\n",
        "    lb=(line.split()[0]).split(\":\")[0]\n",
        "    #print(lb)\n",
        "    if(lb==\"PERS\"):\n",
        "      new_label.append(1)\n",
        "    if(lb==\"LOCA\"):\n",
        "      new_label.append(2)\n",
        "    if(lb==\"ORGA\"):\n",
        "      new_label.append(3)\n",
        "    if(lb==\"DATE\"):\n",
        "      new_label.append(4)\n",
        "    if(lb==\"TIME\"):\n",
        "      new_label.append(5)\n",
        "    if(lb==\"PERC\"):\n",
        "      new_label.append(6)\n",
        "    if(lb==\"NUMB\"):\n",
        "      new_label.append(7)\n",
        "    if(lb==\"CURR\"):\n",
        "      new_label.append(8)\n",
        "    queries.append(line[5:])\n",
        "\n",
        "  vectorizer =TfidfVectorizer(min_df=1)# min_df is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms.\n",
        "  \n",
        "  X = vectorizer.fit_transform(classes) #Hence text converted to vectors to process\n",
        "  Y = vectorizer.fit_transform(queries)\n",
        "\n",
        "  X_ = Y[:len(new_label)]\n",
        "  Y_ = new_label[:len(new_label)]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_, Y_, test_size=0.25, random_state=42)\n",
        "#\tprint(\"X_train = \",X_train.shape)\n",
        "#\tprint(\"X_test = \",X_test.shape)\n",
        "\n",
        "  test=Y[len(queries)-1].toarray()\n",
        "\n",
        "\n",
        "  #nn=MLPClassifier(activation='tanh',solver='sgd',hidden_layer_sizes=(80,50,30,8),random_state=4,alpha=0.1,batch_size=71)#73.9 accuracy\n",
        "\t\n",
        "  nn = LinearSVC(random_state=0, tol=0.3,loss=\"squared_hinge\",multi_class=\"crammer_singer\")#74.4 73.5 76.1\n",
        "  #nn = LogisticRegression(random_state=0, solver='sag', multi_class='multinomial')#71.4 73.9\n",
        "  \n",
        "\n",
        "\t\n",
        "\n",
        "  nn.fit(X_train,y_train)\n",
        "  pred2=nn.predict(X_test)\n",
        "\n",
        "\n",
        "  hits=0.00\n",
        "  for i in range(0,len(y_test)):\n",
        "    if y_test[i]==pred2[i]:\n",
        "      hits=hits+1\n",
        "\t\t\t\n",
        "\n",
        "  #print(\"The accuracy is \",((hits/len(y_test))*100.0))\n",
        "  \n",
        "  \n",
        "\t\n",
        "  result=nn.predict(test)\n",
        "  if(result==1):\n",
        "    ans_type.append(\"PERSON\")\n",
        "\n",
        "  elif(result==2):\n",
        "    ans_type.append(\"LOCATION\")\n",
        "\n",
        "  elif(result==3):\n",
        "    ans_type.append(\"ORGANIZATION\")\n",
        "\n",
        "  elif(result==4):\n",
        "    ans_type.append(\"DATE\")\n",
        "\n",
        "  elif(result==5):\n",
        "    ans_type.append(\"TIME\")\n",
        "\n",
        "  elif(result==6):\n",
        "    ans_type.append(\"PERCENTAGE\")\n",
        "  \n",
        "  elif(result==7):\n",
        "    ans_type.append(\"NUMBER\")\n",
        "  else:\n",
        "    ans_type.append(\"CURRENCY\")\n",
        "  return(ans_type[0])\n",
        "\n",
        "  \n",
        "user_input_telugu=\"“అడ్వెంచర్స్ ఆఫ్ టామ్ సాయర్” రచయిత ఎవరు?\" #input(\"enter query\")\n",
        "ans_type=[]\n",
        "Question_Classification(user_input_telugu)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PERSON'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3VeIeW7a9Zm"
      },
      "source": [
        "#FUNCTION TO FIND SEQUENCE MATCH SCORE BETWEEN TWO STRINGS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdazUGlfFfDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4762505-4686-48f1-8c06-22ad821c2957"
      },
      "source": [
        "\n",
        "#TO find Sequence matching scores\n",
        "def similarity(str1,str2):\n",
        "  str1=str1.lower()\n",
        "  str2=str2.lower()\n",
        "  #print(str1,str2)\n",
        "  \n",
        "  from difflib import SequenceMatcher\n",
        "  score=SequenceMatcher(lambda x: x==\" \",str1,str2).ratio()\n",
        "  \n",
        "  return score\n",
        "similarity(\"venu\",\"M.Venu\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICnNABsObG8z"
      },
      "source": [
        "# FUCTION TO FIND NER TAGS to the WORDS IN A STRING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4EbR2-MofGi",
        "outputId": "90955bd9-a6be-4479-b977-45a5d60fdd83"
      },
      "source": [
        "def ner_tag(sents,tag):\n",
        "  import spacy \n",
        "  from spacy import displacy\n",
        "  if(tag==\"LOCATION\"):\n",
        "    tag=\"GPE\"\n",
        "  if(tag==\"NUMBER\"):\n",
        "    tag=\"CARDINAL\"\n",
        "  if(tag==\"ORGANIZATION\"):\n",
        "    tag=\"ORG\"\n",
        "  if(tag==\"CURRENCY\"):\n",
        "    tag=\"MONEY\"\n",
        "\n",
        "  \n",
        "\n",
        "  # Load SpaCy model\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  #nlp = spacy.load(\"en_core_web_md\")\n",
        "  #nlp = spacy.load(\"en_core_web_lg\")\n",
        "  import pandas as pd\n",
        "  \n",
        "  doc = nlp(sents)\n",
        "\n",
        "  entities = []\n",
        "  labels = []\n",
        "  position_start = []\n",
        "  position_end = []\n",
        "\n",
        "  for ent in doc.ents:\n",
        "    entities.append(ent)\n",
        "    labels.append(ent.label_)\n",
        "    position_start.append(ent.start_char)\n",
        "    position_end.append(ent.end_char)\n",
        "    #print(entities, labels)\n",
        "  \n",
        "  ans=[]  \n",
        "  df = pd.DataFrame({'Entities':entities,'Labels':labels}) #,'Position_Start':position_start, 'Position_End':position_end})\n",
        "  for i in range(0,len(labels)):\n",
        "    if labels[i]==tag:\n",
        "      ans.append(entities[i])\n",
        "  #print(df)\n",
        "\n",
        "  \n",
        "\n",
        "    \n",
        "  print(\"possible answers list is\",ans)\n",
        "  #print(\"final answer is\",ans[0])\n",
        "  #final_ans=ans[0]\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        " \n",
        "  return ans #LIST OF ANSWERS\n",
        "#ner_tag(\"narendra modi on 2-03-2021  gave 1 billion dollars, RS.900, $351 AND 500 dollars supreme court is prime minister  Rs 540 crore of Lom Turkish Togo  lira of india\",\"ORGANIZATION\") \n",
        "#ner_tag(\"Lome 1650\",\"LOCATION\")\n",
        "ner_tag(\"\\n Mark  Twain, MARK TWAIN AND  Narendra modi money 500 dollars should NOT exceed INR 4000 USD 100 per annum.\",\"PERSON\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                Entities   Labels\n",
            "0             (Narendra)      ORG\n",
            "1  (money, 500, dollars)    MONEY\n",
            "2                  (INR)      ORG\n",
            "3       (4000, USD, 100)  PRODUCT\n",
            "possible answers list is []\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKx6QEMle346",
        "outputId": "0ffb4614-5f4b-4cb6-bffb-89eff7684286"
      },
      "source": [
        "def curr_ner(words_list):\n",
        "  #print(words_list)\n",
        "  ans_list=[]\n",
        "  \n",
        "  train=['Turkish lira','Turkish','lira','Birr', 'peso', 'Metical', 'Mark', 'Balboa', 'Ruble', 'Euro', 'Krona', 'Lake', 'Colon', 'Euro', 'Sudanese pound', 'Kina', 'Corona', 'Turkish lira', 'Deutsche Mark', 'Malaysian Dollar', 'Kuwaiti Dinar', 'Inti Soul', 'Drachma', 'pound', 'Bolivar', 'Real', 'New Shekel', 'peso', 'Colon', 'pound', 'Tugrick', 'French Frank', 'American Dollar', 'Shilling', 'Rs. 1000', 'American Dollar', 'Rs 2 crore', 'Rs 540 crore', 'Rs. 115', 'Rs.5,000','₹','₹1234567890','750-million-dollar', '50 pence', 'Rs.650 crore', '1 billion', 'USD 75 million', 'Rs.50,000 crores', 'Rs 2 trillion', 'Rs 2 trillion', 'Euro', '1,01,500', '1,8292 crores', 'USD 15 million']\n",
        "  #print(train)\n",
        "  i=0\n",
        "  for word in words_list:\n",
        "    for word_in_train in train:\n",
        "      sc=similarity(word_in_train,word)\n",
        "      #print(word_in_train,word,sc)\n",
        "      if(sc>=0.7):\n",
        "        ans_list.append(word)\n",
        "    i+=1\n",
        "  print(\"Possible answers list is \",ans_list)\n",
        "  return (ans_list)\n",
        "curr_ner(['Birr',\"nothing\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Possible answers list is  ['Birr']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Birr']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZq6oa-Fbarv"
      },
      "source": [
        "**#MAIN CODE FOR PARAGRAPH EXTRACTION USING SEARCH ENGINES 1.BING   2.GOOGLE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPJ7W_RJDdlL",
        "outputId": "9d22f2b6-e3d3-442a-9aa5-d3ee405fbd96"
      },
      "source": [
        "#Main code starts here\n",
        "import requests, webbrowser\n",
        "import nltk\n",
        "import urllib\n",
        "#nltk.download('punkt')\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "def getting_links(search):\n",
        "  \n",
        "  A = (\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\",\n",
        "       \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36\",\n",
        "       \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36\",\n",
        "      )\n",
        "\n",
        "  Agent = A[random.randrange(len(A))]\n",
        "  headers={'user-agent': Agent}\n",
        "  \n",
        "  r = requests.get(url,headers=headers)\n",
        "  soup = BeautifulSoup(r.content, 'lxml')\n",
        "  \n",
        "  if not(soup.findAll('li', attrs={'class':'b_algo'})):getting_links(search)\n",
        "\t#print(\"Not able to find urls, Some Error came call back the function again....\\n\")\n",
        "  else: \n",
        "    for listt in soup.findAll('li', attrs={'class':'b_algo'}):\n",
        "      head_links = listt.find('h2')\n",
        "      for link in head_links.find_all('a', href=True):\n",
        "        final_links.append(link['href'])\n",
        "  \n",
        "  Numlinks=len(final_links[:-2])\n",
        "  return final_links[:no_of_url]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#A = (\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\",\n",
        "#      \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36\",\n",
        " #      \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36\",\n",
        "  #    )\n",
        "\n",
        "#Agent = A[random.randrange(len(A))]\n",
        "#headers={'user-agent': Agent}\n",
        "\n",
        "#downloaded = drive.CreateFile({'id':'1HBH06-0wdBrC-S4oJNX3pDTdSWry5f5d'}) # replace the id with id of file you want to access\n",
        "#downloaded.GetContentFile('OVER_ALL_QA_DATA.txt') \n",
        "#t = open(\"OVER_ALL_QA_DATA.txt\",\"r\").readlines()\n",
        "#Target_Questions_telugu = []\n",
        "#Target_Answers_telugu\t = []\n",
        "#for line in t:\n",
        "#\tline = line.strip()\n",
        "#\tline = line.split(\":::\")\n",
        "#\tTarget_Answers_telugu.append(line[0].strip())\n",
        "#\tTarget_Questions_telugu.append(line[1].strip())\n",
        "\n",
        "\n",
        " \n",
        "t = open(\"/content/drive/MyDrive/odqa_telugu_testset.txt\",\"r\").readlines()\n",
        "print(len(t))\n",
        "Target_Questions_telugu = []\n",
        "Target_Answers_telugu\t = []\n",
        "\n",
        "for line in t:\n",
        "  line=line.strip()\n",
        "  line=line.split(\"@@@\")\n",
        "  Target_Questions_telugu.append(line[0].strip()[5:])\n",
        "  Target_Answers_telugu.append(line[1].strip())\n",
        "\n",
        "t2 = open(\"/content/drive/MyDrive/odqa_telugu_testset.te.en.txt\",\"r\").readlines()\n",
        "print(len(t2))\n",
        "Target_Questions = []\n",
        "Target_Answers\t = []\n",
        "\n",
        "for line in t2:\n",
        "  line=line.strip()\n",
        "  line=line.split(\"?\")\n",
        "  Target_Questions.append(line[0].strip()[5:]+\"?\")\n",
        "  Target_Answers.append(line[1].strip())\n",
        "\n",
        "\n",
        "#t = open(\"/content/drive/MyDrive/odqa_telugu_testset_english.txt\",\"r\").readlines()\n",
        "\n",
        "n=50 #input(\"no of questions to be checked\")\n",
        "hit=0\n",
        "partial=0\n",
        "partial_2=0\n",
        "engine=input(\"select search engine google/bing \")\n",
        "help=int(input(\"ENTER starting position of tag(like 250 for curr,200 for car,150 for date,100 for org,50 for loc,0 for pers\"))\n",
        "help2=\"\" #USEFUL WHILE FINDING QUESTION CLASSIFICATION ACCURACY\n",
        "#(Target_Questions,Target_Answers)=translate(Target_Questions_telugu[0:n],Target_Answers_telugu[0:n]) # Test questions and Test answers are converted from telugu to english\n",
        "#print(\"checking for conversion to english from telugu\")\n",
        "print(Target_Questions[0+help:n+help])\n",
        "#print(Target_Answers[0:n])\n",
        "\n",
        "z=0\n",
        "count=0\n",
        "final_answer_list=[]\n",
        "for z in range(0,n):\n",
        "  if(z>=0 and z<50):#These conditions useful to find Quesion classification accuracy\n",
        "    help2=\"PERSON\"\n",
        "  if(z>=50 and z<100):\n",
        "    help2=\"LOCATION\"\n",
        "  if(z>=100 and z<150):\n",
        "    help2=\"ORGANIZATION\"\n",
        "  if(z>=150 and z<200):\n",
        "    help2=\"DATE\"\n",
        "  if(z>=200 and z<250):\n",
        "    help2=\"NUMBER\"\n",
        "  if(z>=250 and z<300):\n",
        "   help2=\"CURRENCY\"  \n",
        "  z=z+help\n",
        "\n",
        "  print(\"\\nsearching for question\",z+1,\"..............,\")\n",
        "  print(\"Question: \",Target_Questions[z])\n",
        "\n",
        "  \n",
        "  user_input_telugu=Target_Questions_telugu[z]\n",
        "  user_input=Target_Questions[z]    #input(\"Enter your Query in telugu \")\n",
        "  \n",
        "  ans_type=[]\n",
        "  tag=Question_Classification(user_input_telugu)\n",
        "  print(tag)\n",
        "  \n",
        "  if(tag==help2):\n",
        "    count+=1\n",
        "  #print(\"Quesiotn classification accuracu is \",count*100/50)\n",
        "  \n",
        "  #user_input=translate_2(user_input_telugu)\n",
        "  \n",
        "  if(engine=='google'):\n",
        "    google_search=requests.get(\"https://www.google.com/search?q=\"+user_input)\n",
        "    # print(google_search.text)\n",
        "    soup=BeautifulSoup(google_search.content,'html.parser')\n",
        "    no_of_url=3 #int(input(\"Enter the no of url to get information \"))\n",
        "    no_of_sentences=15 #int(input(\"enter no of sentences to be displayed \"))\n",
        "    templinks=[]\n",
        "    for link in soup.find_all('a'):\n",
        "      if 'href' in link.attrs:\n",
        "        templinks.append(link.attrs['href'])\n",
        "    #print(templinks)\n",
        "    links=[]\n",
        "    for link in templinks:\n",
        "      if (link[1]=='u'): \n",
        "          links.append(link)\n",
        "    #print(links)\n",
        "    final_links=[];\n",
        "    for link in links:\n",
        "      x=link.find('&')\n",
        "      if(x!=-1):\n",
        "        tempstring=link[7:x]\n",
        "        if tempstring not in final_links and (tempstring.find('%')==-1):\n",
        "          if len(final_links)<no_of_url:\n",
        "            final_links.append(link[7:x])\n",
        "          else:\n",
        "            break\n",
        "    #print(final_links)\n",
        "    \n",
        "    \n",
        "  \n",
        "  elif engine=='bing':\n",
        "    no_of_url=3 #int(input(\"Enter the no of url to get information \"))\n",
        "    no_of_sentences=15 #int(input(\"enter no of sentences to be displayed \"))\n",
        "    prelink=f\"https://www.{engine}.com/search?\"\n",
        "    query_args = { 'q':user_input, 'num': no_of_url }\n",
        "    encoded_args = urllib.parse.urlencode(query_args)\n",
        "    url = prelink + encoded_args\n",
        "    final_links=[]\n",
        "    getting_links(user_input)\n",
        "    final_links=final_links[0:no_of_url]\n",
        "    #print(\"lenght of final links list is\",len(final_links))\n",
        "    #print(final_links)\n",
        "    \n",
        "\n",
        "    \n",
        "  \n",
        "  \n",
        "  else:\n",
        "    print(\"you have selected wrong search engine\")\n",
        "    exit()\n",
        "\n",
        "  #print(\"final links are \",final_links)\n",
        "  #soup=[]\n",
        "  #for link in final_links:\n",
        "  #  try:\n",
        "  #   webopen=requests.get(link)\n",
        "    #  soup.append(BeautifulSoup(webopen.content,'lxml'))\n",
        "    #except:\n",
        "    #  pass\n",
        "  soup=[]\n",
        "  for link in final_links:\n",
        "    try:\n",
        "        webopen=requests.get(link)\n",
        "        soup.append(BeautifulSoup(webopen.content,'lxml'))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "  similar={} \n",
        "  titles=[]\n",
        "  for i in range(len(soup)):#looping around each website\n",
        "    try:\n",
        "    #text=soup[i].get_text()\n",
        "      text=[]\n",
        "      #print(soup[i].title.text)\n",
        "      titles.append(soup[i].title.text[0:-11])\n",
        "      for para in soup[i].findAll('p'):# paragraph extration\n",
        "          pa=para.text\n",
        "          text.append(pa) #text is a list whose elements are paragraphs(which contains sentences)\n",
        "      \n",
        "      from nltk import sent_tokenize\n",
        "      from nltk import word_tokenize\n",
        "      sentence=[]\n",
        "      for para in text:\n",
        "        sentence=sent_tokenize(para)# divided content of website into a sentences\n",
        "        #print(len(sentence))\n",
        "        #print(sentence)\n",
        "      \n",
        "      # nltk.download('stopwords')\n",
        "        from nltk.corpus import stopwords\n",
        "        user_input_words=word_tokenize(user_input)\n",
        "        sw=stopwords.words('english')\n",
        "        user_input_final_words={w.lower() for w in user_input_words if not w in sw } #sets\n",
        "      \n",
        "        sentence_words=[]\n",
        "        sentence_final_words=[] #list in which stop words are removed\n",
        "        i=0\n",
        "        \n",
        "        for i in range(0,len(sentence)):\n",
        "          sentence_words.append(word_tokenize(sentence[i]))\n",
        "          sentence_final_words.append({w.lower() for w in sentence_words[i] if not w in sw})\n",
        "          rvector = user_input_final_words.union(sentence_final_words[i]) \n",
        "          v1=[]\n",
        "          v2=[]\n",
        "          for w in rvector:\n",
        "            if w in user_input_final_words:\n",
        "              v1.append(1)\n",
        "            else:\n",
        "              v1.append(0)\n",
        "            if w in sentence_final_words[i]:\n",
        "              v2.append(1)\n",
        "            else:\n",
        "              v2.append(0)\n",
        "          c=0\n",
        "          for j in range(len(rvector)):\n",
        "            c+=v1[j]*v2[j]\n",
        "          v1_square=[v**2 for v in v1]\n",
        "          v2_square=[v**2 for v in v2]\n",
        "          try:\n",
        "            cosine=c/(float((sum(v1_square)*sum(v2_square))**0.5))\n",
        "            similar[sentence[i]]=cosine\n",
        "          except:\n",
        "            pass\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    #print(cosine) \n",
        "    #print(len(cosine))\n",
        "    #print(max(cosine))\n",
        "  \n",
        "    #print(sentence[cosine.index(max(cosine))])\n",
        "  #print(max(similar.values()))\n",
        "\n",
        "  sorted_dict = dict( sorted(similar.items(),\n",
        "                            key=lambda item: item[1],\n",
        "                            reverse=True))\n",
        "  relevant_sent=list(sorted_dict.keys())[:no_of_sentences]\n",
        "  text_of_sent=\"\"\n",
        "  for sent in relevant_sent:\n",
        "    #print(sent)\n",
        "    text_of_sent=text_of_sent+\" \"+sent\n",
        "  for title in titles:\n",
        "    text_of_sent=text_of_sent+\" \"+title\n",
        "\n",
        "  #final_ans=ner_tag(text_of_sent,tag)\n",
        "  \n",
        "  try:\n",
        "    if(tag=='CURRENCY'):\n",
        "      #print(\"OKKKKK\")\n",
        "      words_list=word_tokenize(text_of_sent)\n",
        "      #temp=str(ner_tag(text_of_sent,tag)) #Answer produced by spacy ner for currencu tag\n",
        "      #words_list.append(temp)\n",
        "      ans=curr_ner(words_list)\n",
        "    else:\n",
        "      ans=ner_tag(text_of_sent,tag)\n",
        "    #print(df)\n",
        "    \n",
        "    \n",
        "#    if(str(Target_Answers[z])==str(ans)):      #str(Target_Answers[z]).find(str(ans))!=-1 or str(ans).find(Target_Answers[z])!=-1 ):\n",
        "#      hit+=1\n",
        "  except:\n",
        "    ans=[\"NO ANSWER\"]\n",
        "    #final_answer_list.append(ans)\n",
        "    pass\n",
        "  try:\n",
        "    print('final answer is', ans[0])\n",
        "  except:\n",
        "    ans.append(\"NO ANSWER\")\n",
        "    print('final answer is ',ans[0])\n",
        "  print(\"Actual answer is\",Target_Answers[z])\n",
        "  final_answer_list.append(str(ans[0]))\n",
        "\n",
        "  similar={}\n",
        "  target_ans_words=set()\n",
        "  final_ans_words=set()\n",
        "  target_ans_words=set(word_tokenize(Target_Answers[z]))\n",
        "  final_ans_words=set(word_tokenize(str(ans[0])))\n",
        "  rvector=set()\n",
        "  rvector = target_ans_words.union(final_ans_words) \n",
        "  v1=[] #for target answers\n",
        "  v2=[]\n",
        "  \n",
        "  for w in rvector:\n",
        "    if w in target_ans_words:\n",
        "      v1.append(1)\n",
        "    else:\n",
        "      v1.append(0)\n",
        "    if w in final_ans_words:\n",
        "      v2.append(1)\n",
        "    else:\n",
        "      v2.append(0)\n",
        "  c=0\n",
        "  j=0\n",
        "  try:\n",
        "    for j in range(len(rvector)):\n",
        "      c+=v1[j]*v2[j]\n",
        "    v1_square=[v**2 for v in v1]\n",
        "    v2_square=[v**2 for v in v2]\n",
        "      \n",
        "    cosine2=c/(float((sum(v1_square)*sum(v2_square))**0.5))\n",
        "    print(\"cosine similarity is \",cosine2)\n",
        "     # similar[z]=cosine2\n",
        "  except:\n",
        "    pass\n",
        "  score=similarity(Target_Answers[z],str(ans[0]))\n",
        "  print(\"Sequence matcher score is \",score)\n",
        "  if cosine2==1.0 or score==1.0:\n",
        "    hit+=1\n",
        "  if cosine2>=0.7 or score>=0.7:\n",
        "    partial+=1\n",
        "  if cosine2>=0.4 or score>=0.5:\n",
        "    partial_2+=1\n",
        "  print(\"hits are \",hit,partial,partial_2)\n",
        "        \n",
        "\n",
        "\n",
        "print(\"hits are\",hit)\n",
        "accuracy= hit*100/n\n",
        "print(\"actual answers list is,\",Target_Answers[0+help:n+help])\n",
        "print(\"answers that I got are\",final_answer_list)\n",
        "print(\"Exact match accuracy for\",n,\"no of questions is \",accuracy)\n",
        "\n",
        "print(\"no of partial correct ans are \",partial)\n",
        "partial_accuracy=partial*100/n\n",
        "print(\"partial match accurccy is for \",n,\"no of questions is \",partial_accuracy)\n",
        "\n",
        "print(\"no of partial_2(cosine>=0.5) are \",partial_2)\n",
        "partial_2_accuracy=partial_2*100/n\n",
        "print(\"partial_2 accuracy is for \",n,\"no of questioons is \",partial_2_accuracy)\n",
        "print(\"Quesiton classification accuracy is \",(count*100)/50)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300\n",
            "300\n",
            "select search engine google/bing bing\n",
            "ENTER starting position of tag(like 250 for curr,200 for car,150 for date,100 for org,50 for loc,0 for pers250\n",
            "[' Turkish currency?', ' Which is the Ethiopian currency?', ' What is the currency of Chile?', ' What is the currency of Mozambique?', ' What is the currency of Finland?', ' What is the currency of Panama?', ' What is the currency of Russia?', ' Which is the official currency of the European Union?', ' What is the Swedish currency?', ' What is the currency of Albania?', ' Which is the El Salvador currency?', ' What is the Dutch currency?', ' What is the Sudanese currency?', ' What is the currency of Papua New Guinea?', ' What is the currency of Czechoslovakia?', ' What is the currency of Turkey?', ' What is the German currency (United)?', ' What is the currency of Malaysia?', ' What is the Kuwaiti currency?', ' What is the currency of Peru?', ' What is the Greek currency?', ' What is the currency of Lebanon?', ' What is the currency of Venezuela?', ' What is the currency of Iran?', ' What is the currency of Israel?', ' What is the currency of Chile?', ' What is the currency of Salvador?', ' What is the British currency?', ' What is the currency of Mongolia?', ' What is the Andorra currency?', ' Indian currency is linked to which currency for international payments?', ' What is the Austrian currency?', ' What is the highest value of currency notes currently in legal tender in India?', ' for international payments; Indian currency is associated with which currency?', ' How much annual funding has the Maharashtra Cabinet approved for juvenile homes in the state?', ' How much investment has the central government recently cleared in stuck residential properties?', ' What is the service cost under the newly launched Janasevaka scheme?', ' Under PMMVY, how much money is paid to pregnant women and nursing mothers for the first living child of the family?', ' What is the value of the largest single foreign currency loan recently signed by NTPC?', ' Which new coin was minted by Britain to mark the departure of the country from Brexit?', ' How much did Punjab approve for the revival of Buda Nalla?', ' How much did Exim Bank raise through the sale of foreign bonds to carry out regular operations?', ' How much credit did India give to Cuba for financing solar parks?', ' How many long-term government securities has RBI recently acquired?', ' How many trillions is the Government of India expected to increase the turnover of khadi and village industries in the next five years?', ' How many trillions is the Government of India expected to increase the turnover of khadi and village industries in the next five years?', ' What is Financed Currency?', ' How much valuable funding has been allocated under the Mahatma Gandhi National Rural Employment Guarantee Scheme for the current financial year 2020-2021?', ' How much funding has the Government of India approved for the implementation of JJM in Maharashtra during 2020-21?', ' Gavi - How many dollars has India pledged to donate to the Global Alliance for Vaccines and Immunization?']\n",
            "\n",
            "searching for question 251 ..............,\n",
            "Question:   Turkish currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lira', '200-Turkish-lira', '200-Turkish-lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'lira', 'removal', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'lira', 'lirası', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'lira', 'pound', 'pound', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'lira', 'Turkish', 'Turkish', 'Turkish', 'around', 'around', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'make', 'make', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lirası', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Lira']\n",
            "final answer is Turkish\n",
            "Actual answer is Turkish lira\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.7368421052631579\n",
            "hits are  0 1 1\n",
            "\n",
            "searching for question 252 ..............,\n",
            "Question:   Which is the Ethiopian currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Birr', 'Birr', 'Birr', 'Birr', 'Birr', 'birr', 'birr', 'Birrs', 'Birr', 'Birr', 'birr', 'Birr']\n",
            "final answer is Birr\n",
            "Actual answer is Birr\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  1 2 2\n",
            "\n",
            "searching for question 253 ..............,\n",
            "Question:   What is the currency of Chile?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['peso', 'peso', 'peso', 'peso', 'reales', 'pesos', 'pesos', '1,000', 'pesos', 'pesos', '10-peso', '10-peso', 'peso', 'peso', 'peso', 'peso', 'Peso', 'Peso']\n",
            "final answer is peso\n",
            "Actual answer is peso\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  2 3 3\n",
            "\n",
            "searching for question 254 ..............,\n",
            "Question:   What is the currency of Mozambique?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['metical', 'meticais', 'area', 'Lake', 'metical', 'area', 'meticais', 'metical']\n",
            "final answer is metical\n",
            "Actual answer is Metical\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  3 4 4\n",
            "\n",
            "searching for question 255 ..............,\n",
            "Question:   What is the currency of Finland?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['euro', 'euro', 'euro', 'Malaysian']\n",
            "final answer is euro\n",
            "Actual answer is Mark\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.25\n",
            "hits are  3 4 4\n",
            "\n",
            "searching for question 256 ..............,\n",
            "Question:   What is the currency of Panama?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CURRENCY\n",
            "OKKKKK\n",
            "Possible answers list is  ['Balboa', 'lack', 'real', 'Balboa', 'typical', 'Balboa', 'Balboa', 'Balboa']\n",
            "final answer is Balboa\n",
            "Actual answer is Balboa\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  4 5 5\n",
            "\n",
            "searching for question 257 ..............,\n",
            "Question:   What is the currency of Russia?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Ruble', 'Rubles', 'Read', 'ruble', 'ruble', 'Ruble', 'RUB']\n",
            "final answer is Ruble\n",
            "Actual answer is Ruble\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  5 6 6\n",
            "\n",
            "searching for question 258 ..............,\n",
            "Question:   Which is the official currency of the European Union?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['euro', 'euro', 'euro', 'make', 'make', 'euro', 'euro', 'euro', 'area', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'EUR', 'EUR', 'EUR', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'area', 'euro', 'euro', 'euro', 'removal', 'euro', 'euro', 'euro', 'area', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'euro', 'area', 'Eur', 'Eur', 'Eur', 'euro', 'euro', 'euro', 'Eur', 'Eur', 'Eur']\n",
            "final answer is euro\n",
            "Actual answer is Euro\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  6 7 7\n",
            "\n",
            "searching for question 259 ..............,\n",
            "Question:   What is the Swedish currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Krona', 'Krona', 'Krona', 'Krona', 'krona', 'krona', 'krona', 'krona', 'Krona', 'Krona', 'Krona', 'Krona', 'Krona', 'Krona', 'crown', 'krona', 'krona', 'crown', 'euro', 'euro', 'euro', 'krona', 'krona', 'kronor', 'Krona', 'Krona', 'Denmark', 'Krona', 'Krona', 'Kronor', 'krona', 'krona', 'Krona', 'Krona', 'Krona', 'Krona']\n",
            "final answer is Krona\n",
            "Actual answer is Krona\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  7 8 8\n",
            "\n",
            "searching for question 260 ..............,\n",
            "Question:   What is the currency of Albania?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['really', 'Euro', 'Euro', 'Euro', 'tourist', 'Euro', 'Euro', 'Euro', 'common', 'common', 'euro', 'euro', 'euro', 'EUR', 'EUR', 'EUR']\n",
            "final answer is really\n",
            "Actual answer is Lake\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.2\n",
            "hits are  7 8 8\n",
            "\n",
            "searching for question 261 ..............,\n",
            "Question:   Which is the El Salvador currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Colón', 'Colón', 'colón', 'colón', 'peso', 'peso', 'make', 'make', 'Colón', 'Colón', 'colón', 'colón', 'peso', 'peso', 'reales', 'unable', 'colon', 'colon', 'colon']\n",
            "final answer is Colón\n",
            "Actual answer is Colon\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.8\n",
            "hits are  7 9 9\n",
            "\n",
            "searching for question 262 ..............,\n",
            "Question:   What is the Dutch currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['euro', 'euro', 'euro', 'Europe', 'Europe', 'Europe', 'euro', 'euro', 'euro']\n",
            "final answer is euro\n",
            "Actual answer is Euro\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  8 10 10\n",
            "\n",
            "searching for question 263 ..............,\n",
            "Question:   What is the Sudanese currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Sudanese', 'pound', 'pound', 'Sudanese', 'pound', 'pound', 'Sudanese', 'pound', 'pound', 'Sudanese', 'Pound', 'Pound', 'Sudanese', 'pound', 'pound', 'Sudanese', 'rule', 'Sudanese', 'Sudanese', 'pound', 'pound', 'pound', 'pound', 'Sudanese', 'Sudanese', 'Sudanese', 'pound', 'pound', 'Sudanese', 'pound', 'pound']\n",
            "final answer is Sudanese\n",
            "Actual answer is Sudanese pound\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.7272727272727273\n",
            "hits are  8 11 11\n",
            "\n",
            "searching for question 264 ..............,\n",
            "Question:   What is the currency of Papua New Guinea?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['kina', 'Kina', 'Kina', 'Kina', 'Kina', 'Kina', 'Kina', 'Kina', 'Stirling', 'Pound', 'Pound', 'Kina', 'Kina', 'Pound', 'Pound', 'Kina', 'kina', 'kina', 'kina', 'kina', 'kina', 'kina', 'kina', 'kina', 'Kina']\n",
            "final answer is kina\n",
            "Actual answer is Kina\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  9 12 12\n",
            "\n",
            "searching for question 265 ..............,\n",
            "Question:   What is the currency of Czechoslovakia?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Koruna', 'koruna', 'Koruna', 'Koruna', 'koruna', 'crown', 'Koruna', 'Koruna', 'Crown', 'Koruna', 'Koruna', 'crown', 'koruna']\n",
            "final answer is Koruna\n",
            "Actual answer is koruna\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  10 13 13\n",
            "\n",
            "searching for question 266 ..............,\n",
            "Question:   What is the currency of Turkey?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'lira', 'EUR', 'EUR', 'EUR', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Euros', 'Euros', 'Euros', 'retails', 'markets', 'Tourism', 'removal', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Tourism', 'lira', 'Turkish', 'Turkish', 'Turkish', 'around', 'around', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lirası', 'Turkish', 'Turkish', 'Turkish', 'Lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'lira', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish', 'Turkish']\n",
            "final answer is Turkish\n",
            "Actual answer is Turkish lira\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.7368421052631579\n",
            "hits are  10 14 14\n",
            "\n",
            "searching for question 267 ..............,\n",
            "Question:   What is the German currency (United)?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Euro', 'Euro', 'Euro', 'Mark', 'Deutsche', 'Mark', 'Euro', 'Euro', 'Euro', 'mark', 'Mark', 'Deutsche', 'Mark', 'D-Mark', 'Mark', 'Deutsche', 'Mark', 'Deutsche', 'Mark', 'mark', 'D-Mark', 'Euro', 'Euro', 'Euro', 'Deutsche', 'Mark']\n",
            "final answer is Euro\n",
            "Actual answer is Deutsche Mark\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.35294117647058826\n",
            "hits are  10 14 14\n",
            "\n",
            "searching for question 268 ..............,\n",
            "Question:   What is the currency of Malaysia?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Malaysian', 'Tourist', 'Malaysian']\n",
            "final answer is Malaysian\n",
            "Actual answer is Malaysian Dollar\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.72\n",
            "hits are  10 15 15\n",
            "\n",
            "searching for question 269 ..............,\n",
            "Question:   What is the Kuwaiti currency?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CURRENCY\n",
            "OKKKKK\n",
            "Possible answers list is  ['Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Iraq', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti', 'Kuwaiti']\n",
            "final answer is Kuwaiti\n",
            "Actual answer is Kuwaiti Dinar\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.7\n",
            "hits are  10 16 16\n",
            "\n",
            "searching for question 270 ..............,\n",
            "Question:   What is the currency of Peru?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['read', 'Lima', 'Fake', 'common', 'common']\n",
            "final answer is read\n",
            "Actual answer is Inti Soul\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.0\n",
            "hits are  10 16 16\n",
            "\n",
            "searching for question 271 ..............,\n",
            "Question:   What is the Greek currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Malaysian', 'Euro', 'Euro', 'Euro', 'drachma']\n",
            "final answer is Malaysian\n",
            "Actual answer is Drachma\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.25\n",
            "hits are  10 16 16\n",
            "\n",
            "searching for question 272 ..............,\n",
            "Question:   What is the currency of Lebanon?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CURRENCY\n",
            "OKKKKK\n",
            "Possible answers list is  ['pound', 'pound', 'pound', 'pound', 'pound', 'pound', 'pound', 'pound', 'market', 'pound', 'pound', 'lira', 'līra', 'read', 'pounds', 'pounds', 'pound', 'pound', 'Pound', 'Pound']\n",
            "final answer is pound\n",
            "Actual answer is pound\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  11 17 17\n",
            "\n",
            "searching for question 273 ..............,\n",
            "Question:   What is the currency of Venezuela?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['bolívar', 'bolívar', 'market', 'billion', 'bolívares', 'bolívar', 'Bolívar']\n",
            "final answer is bolívar\n",
            "Actual answer is Bolivar\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.8571428571428571\n",
            "hits are  11 18 18\n",
            "\n",
            "searching for question 274 ..............,\n",
            "Question:   What is the currency of Iran?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Iran', 'take', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'Iran', 'iran', 'Iran', 'Iran', 'Iran', 'Iran', 'rial', 'Iran']\n",
            "final answer is Iran\n",
            "Actual answer is Rial\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.5\n",
            "hits are  11 18 19\n",
            "\n",
            "searching for question 275 ..............,\n",
            "Question:   What is the currency of Israel?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Shekels', 'shekel', 'read', 'shekel', 'shekel', 'spelling', 'shekel', 'shekels', 'pound', 'pound', 'pound', 'pound', 'lira', 'shekel', 'shekel', 'Shekel', 'common', 'common', 'like', 'shekel']\n",
            "final answer is Shekels\n",
            "Actual answer is New Shekel\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.7058823529411765\n",
            "hits are  11 19 20\n",
            "\n",
            "searching for question 276 ..............,\n",
            "Question:   What is the currency of Chile?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['peso', 'peso', 'peso', 'peso', 'peso', 'peso', 'peso', 'peso', 'make', 'make', 'common', 'common', 'markets', 'like', 'peso', 'peso', 'peso', 'peso', 'Peso', 'Peso']\n",
            "final answer is peso\n",
            "Actual answer is peso\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  12 20 21\n",
            "\n",
            "searching for question 277 ..............,\n",
            "Question:   What is the currency of Salvador?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['colon', 'colon', 'colon', 'peso', 'peso', 'colon', 'colon', 'colon', 'peso', 'peso', 'real', 'peso', 'peso', 'colon', 'colon', 'colon']\n",
            "final answer is colon\n",
            "Actual answer is Colon\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  13 21 22\n",
            "\n",
            "searching for question 278 ..............,\n",
            "Question:   What is the British currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['pound', 'pound', 'Euros', 'Euros', 'Euros', 'pound', 'pound', 'Europe', 'Europe', 'Europe', 'like', 'Shilling']\n",
            "final answer is pound\n",
            "Actual answer is pound\n",
            "cosine similarity is  1.0\n",
            "Sequence matcher score is  1.0\n",
            "hits are  14 22 23\n",
            "\n",
            "searching for question 279 ..............,\n",
            "Question:   What is the currency of Mongolia?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['tugrik', 'make', 'make', 'RUB', 'make', 'make', 'deal', 'make', 'make']\n",
            "final answer is tugrik\n",
            "Actual answer is Tugrick\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.9230769230769231\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 280 ..............,\n",
            "Question:   What is the Andorra currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Euro', 'Euro', 'Euro', 'Euro', 'Euro', 'Euro', 'EUR', 'EUR', 'EUR', 'Euro', 'Euro', 'Euro', 'EUR', 'EUR', 'EUR', 'Euro', 'Euro', 'Euro', 'Europe', 'Europe', 'Europe', 'EURO', 'EURO', 'EURO', 'Euro', 'Euro', 'Euro', 'really', 'Euros', 'Euros', 'Euros', 'lacked', 'EURO', 'EURO', 'EURO']\n",
            "final answer is Euro\n",
            "Actual answer is French Frank\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.125\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 281 ..............,\n",
            "Question:   Indian currency is linked to which currency for international payments?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['selling', 'market']\n",
            "final answer is selling\n",
            "Actual answer is American Dollar\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.2727272727272727\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 282 ..............,\n",
            "Question:   What is the Austrian currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Malaysian']\n",
            "final answer is Malaysian\n",
            "Actual answer is Shilling\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.35294117647058826\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 283 ..............,\n",
            "Question:   What is the highest value of currency notes currently in legal tender in India?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CURRENCY\n",
            "OKKKKK\n",
            "Possible answers list is  ['Aske', 'Read']\n",
            "final answer is Aske\n",
            "Actual answer is Rs. 1000\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.16666666666666666\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 284 ..............,\n",
            "Question:   for international payments; Indian currency is associated with which currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['Con', 'Con']\n",
            "final answer is Con\n",
            "Actual answer is American Dollar\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.2222222222222222\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 285 ..............,\n",
            "Question:   How much annual funding has the Maharashtra Cabinet approved for juvenile homes in the state?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['lack', 'found', 'found', 'schooling', 'like', 'lack']\n",
            "final answer is lack\n",
            "Actual answer is Rs 2 crore\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.14285714285714285\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 286 ..............,\n",
            "Question:   How much investment has the central government recently cleared in stuck residential properties?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['real', 'real', 'Real']\n",
            "final answer is real\n",
            "Actual answer is Rs 540 crore\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.25\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 287 ..............,\n",
            "Question:   What is the service cost under the newly launched Janasevaka scheme?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['like', 'like']\n",
            "final answer is like\n",
            "Actual answer is Rs. 115\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.0\n",
            "hits are  14 23 24\n",
            "\n",
            "searching for question 288 ..............,\n",
            "Question:   Under PMMVY, how much money is paid to pregnant women and nursing mothers for the first living child of the family?\n",
            "NUMBER\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                          Entities       Labels\n",
            "0                                           (6000)     CARDINAL\n",
            "1                                          (first)      ORDINAL\n",
            "2                                (Pradhan, Mantri)       PERSON\n",
            "3                                (Vandana, Yojana)       PERSON\n",
            "4                                (Pradhan, Mantri)       PERSON\n",
            "5                                (Vandana, Yojana)       PERSON\n",
            "6                     (Narendra, Modi, Government)          ORG\n",
            "7                                          (69.49)        MONEY\n",
            "8                                          (first)      ORDINAL\n",
            "9                    (the, Pradhan, Mantri, Matru)          ORG\n",
            "10                               (Vandana, Yojana)       PERSON\n",
            "11                                         (48, %)      PERCENT\n",
            "12                                         (39, %)      PERCENT\n",
            "13                                            (UP)          GPE\n",
            "14                                         (Khera)       PERSON\n",
            "15                                         (Drèze)       PERSON\n",
            "16                                         (Khera)       PERSON\n",
            "17                                         (Drèze)       PERSON\n",
            "18            (the, National, Food, Security, Act)          ORG\n",
            "19  (Ministry, of, Women, and, Child, Development)          ORG\n",
            "20                              (1, January, 2017)         DATE\n",
            "21                               (Pradhan, Mantri)       PERSON\n",
            "22                               (Vandana, Yojana)       PERSON\n",
            "23                                          (FLSA)  WORK_OF_ART\n",
            "24                                         (State)          ORG\n",
            "25                                       (1, year)         DATE\n",
            "26                                          (FLSA)         DATE\n",
            "27                                    (Section, 7)          LAW\n",
            "28                                         (State)          ORG\n",
            "29                               (Pradhan, Mantri)       PERSON\n",
            "30                               (Vandana, Yojana)       PERSON\n",
            "31  (Ministry, of, Women, and, Child, Development)          ORG\n",
            "32                                         (India)          GPE\n",
            "33                                           (one)     CARDINAL\n",
            "34                                            (73)        MONEY\n",
            "35            (Break, Time, for, Nursing, Mothers)          ORG\n",
            "36                        (Departme, PM, Modi, 's)       PERSON\n",
            "37                                        (Indian)         NORP\n",
            "possible answers list is [6000, one]\n",
            "final answer is 6000\n",
            "Actual answer is Rs.5,000\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.5\n",
            "hits are  14 23 25\n",
            "\n",
            "searching for question 289 ..............,\n",
            "Question:   What is the value of the largest single foreign currency loan recently signed by NTPC?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['million']\n",
            "final answer is million\n",
            "Actual answer is 750-million-dollar\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.56\n",
            "hits are  14 23 26\n",
            "\n",
            "searching for question 290 ..............,\n",
            "Question:   Which new coin was minted by Britain to mark the departure of the country from Brexit?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CURRENCY\n",
            "OKKKKK\n",
            "Possible answers list is  ['pence', 'mark', 'pence', 'mark', 'pence', 'marks', 'take', 'marks', 'deal', 'million', 'million', 'mark', 'pence', 'mark']\n",
            "final answer is pence\n",
            "Actual answer is 50 pence\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.7692307692307693\n",
            "hits are  14 24 27\n",
            "\n",
            "searching for question 291 ..............,\n",
            "Question:   How much did Punjab approve for the revival of Buda Nalla?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['rule', 'rule', 'rule']\n",
            "final answer is rule\n",
            "Actual answer is Rs.650 crore\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.25\n",
            "hits are  14 24 27\n",
            "\n",
            "searching for question 292 ..............,\n",
            "Question:   How much did Exim Bank raise through the sale of foreign bonds to carry out regular operations?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['billion', 'billion', 'Market', 'market', 'Market', 'billion', 'billion']\n",
            "final answer is billion\n",
            "Actual answer is 1 billion\n",
            "cosine similarity is  0.7071067811865475\n",
            "Sequence matcher score is  0.875\n",
            "hits are  14 25 28\n",
            "\n",
            "searching for question 293 ..............,\n",
            "Question:   How much credit did India give to Cuba for financing solar parks?\n",
            "ORGANIZATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "       Entities  Labels\n",
            "0  (Joe, Biden)  PERSON\n",
            "1      (Turkey)     GPE\n",
            "possible answers list is []\n",
            "final answer is  NO ANSWER\n",
            "Actual answer is USD 75 million\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.08695652173913043\n",
            "hits are  14 25 28\n",
            "\n",
            "searching for question 294 ..............,\n",
            "Question:   How many long-term government securities has RBI recently acquired?\n",
            "ORGANIZATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                               Entities  Labels\n",
            "0                               (March)    DATE\n",
            "1                                 (RBI)     ORG\n",
            "2                                (Bill)  PERSON\n",
            "3     (Liquidity, Adjustment, Facility)     ORG\n",
            "4                         (Re, -, repo)  PERSON\n",
            "5                                (2026)    DATE\n",
            "6                                (2029)    DATE\n",
            "7                                (2031)    DATE\n",
            "8                                 (RBI)     ORG\n",
            "9          (the, Government, of, India)     ORG\n",
            "10                                (RBI)     ORG\n",
            "11  (http://www.rbi.org.in, /, Scripts)     ORG\n",
            "12     (Government, Securities, Market)     ORG\n",
            "13                              (India)     GPE\n",
            "14       (₹1, Reserve, Bank, of, India)     ORG\n",
            "possible answers list is [RBI, Liquidity Adjustment Facility, RBI, the Government of India, RBI, http://www.rbi.org.in/Scripts, Government Securities Market, ₹1 Reserve Bank of India]\n",
            "final answer is RBI\n",
            "Actual answer is Rs.50,000 crores\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.10526315789473684\n",
            "hits are  14 25 28\n",
            "\n",
            "searching for question 295 ..............,\n",
            "Question:   How many trillions is the Government of India expected to increase the turnover of khadi and village industries in the next five years?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['like', 'Make', 'Make', 'Trillion', 'Trillion', 'Trillion', 'trillion', 'trillion', 'trillion', 'Market']\n",
            "final answer is like\n",
            "Actual answer is Rs 2 trillion\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.23529411764705882\n",
            "hits are  14 25 28\n",
            "\n",
            "searching for question 296 ..............,\n",
            "Question:   How many trillions is the Government of India expected to increase the turnover of khadi and village industries in the next five years?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['trillion', 'trillion', 'trillion', 'Trillion', 'Trillion', 'Trillion', 'make', 'make', 'realise', 'trillion-dollar', 'trillion', 'trillion', 'trillion', 'Trillion', 'Trillion', 'Trillion', 'Trillion', 'Trillion', 'Trillion']\n",
            "final answer is trillion\n",
            "Actual answer is Rs 2 trillion\n",
            "cosine similarity is  0.5773502691896258\n",
            "Sequence matcher score is  0.7619047619047619\n",
            "hits are  14 26 29\n",
            "\n",
            "searching for question 297 ..............,\n",
            "Question:   What is Financed Currency?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['markets', 'market', 'markets', 'EUR', 'EUR', 'EUR']\n",
            "final answer is markets\n",
            "Actual answer is Euro\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.18181818181818182\n",
            "hits are  14 26 29\n",
            "\n",
            "searching for question 298 ..............,\n",
            "Question:   How much valuable funding has been allocated under the Mahatma Gandhi National Rural Employment Guarantee Scheme for the current financial year 2020-2021?\n",
            "DATE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                                             Entities    Labels\n",
            "0   (Mahatma, Gandhi, National, Rural, Employment,...       ORG\n",
            "1                                       (2019, -, 20)      DATE\n",
            "2                                            (61,500)  CARDINAL\n",
            "3                                           (MGNREGA)       ORG\n",
            "4                                    (last, year, 's)      DATE\n",
            "5                                            (71,002)  CARDINAL\n",
            "6                                   (13.4, per, cent)     MONEY\n",
            "7                                            (60,000)  CARDINAL\n",
            "8                   (the, Union, Budget, 2019, -, 20)       ORG\n",
            "9                                            (11,002)  CARDINAL\n",
            "10                                        (the, year)      DATE\n",
            "11                                           (267.98)  CARDINAL\n",
            "12                   (the, fiscal, year, 2018, -, 19)      DATE\n",
            "13                                     (Person, days)      DATE\n",
            "14                                           (208.54)  CARDINAL\n",
            "15                             (the, current, fiscal)      DATE\n",
            "16                            (nearly, 15, per, cent)     MONEY\n",
            "17                             (the, current, fiscal)      DATE\n",
            "18                           (the, past, four, years)      DATE\n",
            "19                     (the, only, year, 2017, -, 18)      DATE\n",
            "20                                   (100, per, cent)     MONEY\n",
            "21                                  (97.9, per, cent)     MONEY\n",
            "22                                              (L&T)    PERSON\n",
            "23                                            (Adani)    PERSON\n",
            "24                             (year, -, on, -, year)      DATE\n",
            "25                                  (FY16, and, FY19)   PRODUCT\n",
            "26                                  (29.1, per, cent)     MONEY\n",
            "27                                  (14.4, per, cent)     MONEY\n",
            "28                                  (12.1, per, cent)     MONEY\n",
            "29                                   (7.3, per, cent)     MONEY\n",
            "30                                     (7, per, cent)     MONEY\n",
            "31                                             (FY20)       GPE\n",
            "32                                           (MNREGA)       ORG\n",
            "33                             (year, -, to, -, date)      DATE\n",
            "34                                  (83.6, per, cent)     MONEY\n",
            "35                            (the, previous, fiscal)      DATE\n",
            "36                                             (Govt)   PRODUCT\n",
            "37                                              (LIC)       ORG\n",
            "38                                             (BPCL)       ORG\n",
            "39                                       (Air, India)       ORG\n",
            "40                                     (Budget, 2020)       LAW\n",
            "41                                             (Govt)   PRODUCT\n",
            "42                                          (MGNREGA)       ORG\n",
            "43                                           (60,000)  CARDINAL\n",
            "44  (Budget, for, Rural, Employment, :, Budget, 2020)       LAW\n",
            "45                                            (13, %)   PERCENT\n",
            "possible answers list is [2019-20, last year's, the year, the fiscal year 2018-19, Person days, the current fiscal, the current fiscal, the past four years, the only year 2017-18, year-on-year, year-to-date, the previous fiscal]\n",
            "final answer is 2019-20\n",
            "Actual answer is 1,01,500\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.4\n",
            "hits are  14 26 29\n",
            "\n",
            "searching for question 299 ..............,\n",
            "Question:   How much funding has the Government of India approved for the implementation of JJM in Maharashtra during 2020-21?\n",
            "ORGANIZATION\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                           Entities       Labels\n",
            "0                           (India)          GPE\n",
            "1                             (JJM)          ORG\n",
            "2                     (Maharashtra)          ORG\n",
            "3                     (2020, -, 21)         DATE\n",
            "4                           (India)          GPE\n",
            "..                              ...          ...\n",
            "60  (Meghalaya, ,, Assam, &, Bihar)          ORG\n",
            "61           (Jal, Jeevan, Mission)       PERSON\n",
            "62                   (Jharkhand, &)          ORG\n",
            "63            (GK, Questions, 2020)  WORK_OF_ART\n",
            "64                       (June, 18)         DATE\n",
            "\n",
            "[65 rows x 2 columns]\n",
            "possible answers list is [JJM, Maharashtra, JJM, State, JJM, Government of India, India News Centre, AAP, National Committee, Parameswaran Iyer, Drinking Water & Sanitation, Ministry of Jal Shakti, State, central allocation &, State, State, JJM, CM, State, State, JJM, CM, the QS World University Rankings 2021, The Reserve Bank of India, Bank, JJM, Meghalaya, Assam & Bihar, Jharkhand &]\n",
            "final answer is JJM\n",
            "Actual answer is 1,8292 crores\n",
            "cosine similarity is  0.0\n",
            "Sequence matcher score is  0.0\n",
            "hits are  14 26 29\n",
            "\n",
            "searching for question 300 ..............,\n",
            "Question:   Gavi - How many dollars has India pledged to donate to the Global Alliance for Vaccines and Immunization?\n",
            "CURRENCY\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "OKKKKK\n",
            "Possible answers list is  ['million', 'million', 'million', 'million', 'million']\n",
            "final answer is million\n",
            "Actual answer is USD 15 million\n",
            "cosine similarity is  0.5773502691896258\n",
            "Sequence matcher score is  0.6666666666666666\n",
            "hits are  14 26 30\n",
            "hits are 14\n",
            "actual answers list is, ['Turkish lira', 'Birr', 'peso', 'Metical', 'Mark', 'Balboa', 'Ruble', 'Euro', 'Krona', 'Lake', 'Colon', 'Euro', 'Sudanese pound', 'Kina', 'koruna', 'Turkish lira', 'Deutsche Mark', 'Malaysian Dollar', 'Kuwaiti Dinar', 'Inti Soul', 'Drachma', 'pound', 'Bolivar', 'Rial', 'New Shekel', 'peso', 'Colon', 'pound', 'Tugrick', 'French Frank', 'American Dollar', 'Shilling', 'Rs. 1000', 'American Dollar', 'Rs 2 crore', 'Rs 540 crore', 'Rs. 115', 'Rs.5,000', '750-million-dollar', '50 pence', 'Rs.650 crore', '1 billion', 'USD 75 million', 'Rs.50,000 crores', 'Rs 2 trillion', 'Rs 2 trillion', 'Euro', '1,01,500', '1,8292 crores', 'USD 15 million']\n",
            "answers that I got are ['Turkish', 'Birr', 'peso', 'metical', 'euro', 'Balboa', 'Ruble', 'euro', 'Krona', 'really', 'Colón', 'euro', 'Sudanese', 'kina', 'Koruna', 'Turkish', 'Euro', 'Malaysian', 'Kuwaiti', 'read', 'Malaysian', 'pound', 'bolívar', 'Iran', 'Shekels', 'peso', 'colon', 'pound', 'tugrik', 'Euro', 'selling', 'Malaysian', 'Aske', 'Con', 'lack', 'real', 'like', '6000', 'million', 'pence', 'rule', 'billion', 'NO ANSWER', 'RBI', 'like', 'trillion', 'markets', '2019-20', 'JJM', 'million']\n",
            "Exact match accuracy for 50 no of questions is  28.0\n",
            "no of partial correct ans are  26\n",
            "partial match accurccy is for  50 no of questions is  52.0\n",
            "no of partial_2(cosine>=0.5) are  30\n",
            "partial_2 accuracy is for  50 no of questioons is  60.0\n",
            "Quesiton classification accuracy is  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csVVETD9wg_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d622f372-a336-44a3-b8fa-e7169ac26be1"
      },
      "source": [
        "pip freeze\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2021.5.30\n",
            "cffi==1.14.5\n",
            "cftime==1.5.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.4\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.269\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==4.0.0.2\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.31.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.34.1\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.2\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.4\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.5.0\n",
            "importlib-resources==5.1.4\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "install==1.3.4\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.5\n",
            "Keras==2.4.3\n",
            "keras-nightly==2.5.0.dev2021032900\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.8.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.12.2\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.1\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.4.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.11.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.2\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.1.0\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.5\n",
            "rsa==4.7.2\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.4\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.1.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.18\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.10.1\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.6.14\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.9.0+cu102\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.10.0\n",
            "torchvision==0.10.0+cu102\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}